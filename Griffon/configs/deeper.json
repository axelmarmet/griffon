{
    "seed" : 0,

    "training":{
        "warmup_steps" : 2000,
        "lr_mult"      : 0.1,
        "epochs"       : 30,
        "batch_size"   : 128
    },

    "architecture":{
        "embedding_dim":512,
        "num_subtokens":5,
        "activation_fn":"gelu",
        "code_transformer":{
            "num_layers":4,
            "encoder_layer":{
                "d_model":512,
                "nhead":8,
                "dim_feedforward":1024,
                "num_relative_distances":4
            },
            "norm":{
                "type":"layer_norm",
                "eps":1e-5,
                "d_model":512
            }
        }
    }
}