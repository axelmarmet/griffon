{
    "seed" : 0,

    "training":{
        "warmup_steps"         : 2000,
        "lr_mult"              : 0.1,
        "epochs"               : 30,
        "batch_size"           : 128,
        "simulated_batch_size" : 128
    },

    "architecture":{
        "subtoken_embedding_dim":512,
        "token_embedding_dim":512,
        "num_subtokens":5,
        "scale_token_embeddings":true,
        "activation_fn":"gelu",
        "code_transformer":{
            "num_layers":2,
            "encoder_layer":{
                "d_model":512,
                "nhead":8,
                "dim_feedforward":1024,
                "num_relative_distances":4
            },
            "norm":{
                "type":"layer_norm",
                "eps":1e-5,
                "d_model":512
            }
        }
    }
}