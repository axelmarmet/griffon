{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import pickle\n",
    "\n",
    "from griffon.utils import load_config\n",
    "from griffon.preprocessing.pipeline.stage2.vocab import VocabTransform\n",
    "from griffon.preprocessing.graph.distances import PersonalizedPageRank, ShortestPaths, AncestorShortestPaths, SiblingShortestPaths, DistanceBinning\n",
    "from griffon.preprocessing.graph.binning import ExponentialBinning\n",
    "from griffon.preprocessing.graph.transform import DistancesTransformer\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(vocab_path=\"../../../../../models/vocab.pickle\", \n",
    "                 config_file=\"../../../../../configs/config.json\",\n",
    "                 stage1_root=\"../../../../../data/processed/stage1\")\n",
    "\n",
    "vocab = pickle.load(open(args.vocab_path, \"rb\"))\n",
    "\n",
    "vocab_transform = VocabTransform(vocab)\n",
    "\n",
    "config = load_config(args.config_file)\n",
    "\n",
    "# Extract how distances should be computed from the dataset config\n",
    "distances_config = config['distances']\n",
    "PPR_ALPHA = distances_config['ppr_alpha']\n",
    "PPR_USE_LOG = distances_config['ppr_use_log']\n",
    "PPR_THRESHOLD = distances_config['ppr_threshold']\n",
    "\n",
    "SP_THRESHOLD = distances_config['sp_threshold']\n",
    "\n",
    "ANCESTOR_SP_FORWARD = distances_config['ancestor_sp_forward']\n",
    "ANCESTOR_SP_BACKWARD = distances_config['ancestor_sp_backward']\n",
    "ANCESTOR_SP_NEGATIVE_REVERSE_DISTS = distances_config['ancestor_sp_negative_reverse_dists']\n",
    "ANCESTOR_SP_THRESHOLD = distances_config['ancestor_sp_threshold']\n",
    "\n",
    "SIBLING_SP_FORWARD = distances_config['sibling_sp_forward']\n",
    "SIBLING_SP_BACKWARD = distances_config['sibling_sp_backward']\n",
    "SIBLING_SP_NEGATIVE_REVERSE_DISTS = distances_config['sibling_sp_negative_reverse_dists']\n",
    "SIBLING_SP_THRESHOLD = distances_config['sibling_sp_threshold']\n",
    "\n",
    "# Extract how distances should be binned from the dataset config\n",
    "binning_config = config['binning']\n",
    "EXPONENTIAL_BINNING_GROWTH_FACTOR = binning_config['exponential_binning_growth_factor']\n",
    "N_FIXED_BINS = binning_config['n_fixed_bins']\n",
    "NUM_BINS = binning_config['num_bins']\n",
    "\n",
    "distance_metrics = [\n",
    "    PersonalizedPageRank(threshold=PPR_THRESHOLD, log=PPR_USE_LOG, alpha=PPR_ALPHA),\n",
    "    ShortestPaths(threshold=SP_THRESHOLD),\n",
    "    AncestorShortestPaths(forward=ANCESTOR_SP_FORWARD, backward=ANCESTOR_SP_BACKWARD,\n",
    "                          negative_reverse_dists=ANCESTOR_SP_NEGATIVE_REVERSE_DISTS,\n",
    "                          threshold=ANCESTOR_SP_THRESHOLD),\n",
    "    SiblingShortestPaths(forward=SIBLING_SP_FORWARD, backward=SIBLING_SP_BACKWARD,\n",
    "                         negative_reverse_dists=SIBLING_SP_NEGATIVE_REVERSE_DISTS,\n",
    "                         threshold=SIBLING_SP_THRESHOLD)]\n",
    "\n",
    "db = DistanceBinning(NUM_BINS, N_FIXED_BINS, ExponentialBinning(EXPONENTIAL_BINNING_GROWTH_FACTOR))\n",
    "\n",
    "distances_transformer = DistancesTransformer(distance_metrics, db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal : goal Logic Init Coq eq 0 Compare_Nat Lib_Numerals Factorization Hardware order 0 Compare_Nat Lib_Numerals Factorization Hardware comparison ValB Datatypes Init Coq nat 0 2 n Cons n x X ValB Datatypes Init Coq nat 0 2 n Cons n y Y Compare_Nat Lib_Numerals Factorization Hardware order 0 1\n",
      "Stage2Statement(name='goal', tokens=[Stage1Token(subtokens=[71]), Stage1Token(subtokens=[6]), Stage1Token(subtokens=[4]), Stage1Token(subtokens=[2]), Stage1Token(subtokens=[23]), Stage1Token(subtokens=[3]), Stage1Token(subtokens=[2830, 96]), Stage1Token(subtokens=[951, 1319]), Stage1Token(subtokens=[1830]), Stage1Token(subtokens=[1653]), Stage1Token(subtokens=[782]), Stage1Token(subtokens=[3]), Stage1Token(subtokens=[2830, 96]), Stage1Token(subtokens=[951, 1319]), Stage1Token(subtokens=[1830]), Stage1Token(subtokens=[1653]), Stage1Token(subtokens=[197]), Stage1Token(subtokens=[4429]), Stage1Token(subtokens=[5]), Stage1Token(subtokens=[4]), Stage1Token(subtokens=[2]), Stage1Token(subtokens=[17]), Stage1Token(subtokens=[3]), Stage1Token(subtokens=[19]), Stage1Token(subtokens=[39]), Stage1Token(subtokens=[5020]), Stage1Token(subtokens=[39]), Stage1Token(subtokens=[30]), Stage1Token(subtokens=[129]), Stage1Token(subtokens=[4429]), Stage1Token(subtokens=[5]), Stage1Token(subtokens=[4]), Stage1Token(subtokens=[2]), Stage1Token(subtokens=[17]), Stage1Token(subtokens=[3]), Stage1Token(subtokens=[19]), Stage1Token(subtokens=[39]), Stage1Token(subtokens=[5020]), Stage1Token(subtokens=[39]), Stage1Token(subtokens=[61]), Stage1Token(subtokens=[198]), Stage1Token(subtokens=[2830, 96]), Stage1Token(subtokens=[951, 1319]), Stage1Token(subtokens=[1830]), Stage1Token(subtokens=[1653]), Stage1Token(subtokens=[782]), Stage1Token(subtokens=[3]), Stage1Token(subtokens=[12])], adjacency_matrix=tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64), distances=[(tensor([[ 3,  4, 12,  ...,  0,  0, 25],\n",
      "        [ 8,  4, 19,  ...,  0,  0,  0],\n",
      "        [ 6,  7,  4,  ..., 28, 21, 14],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ...,  5, 18, 25],\n",
      "        [ 0,  0,  0,  ..., 18,  5, 18],\n",
      "        [31,  0, 27,  ..., 25, 18,  5]]), tensor([1.0000e+04, 8.3215e-01, 1.0970e+00, 1.2986e+00, 1.4449e+00, 1.5777e+00,\n",
      "        1.8016e+00, 1.9745e+00, 2.1359e+00, 2.2803e+00, 2.4307e+00, 2.5347e+00,\n",
      "        2.6754e+00, 2.8135e+00, 2.9501e+00, 3.1508e+00, 3.2575e+00, 3.3882e+00,\n",
      "        3.4718e+00, 3.6004e+00, 3.7380e+00, 3.8864e+00, 3.9936e+00, 4.1101e+00,\n",
      "        4.2187e+00, 4.3428e+00, 4.4575e+00, 4.5566e+00, 4.6805e+00, 4.7771e+00,\n",
      "        4.9081e+00, 4.9996e+00]), 'ppr'), (tensor([[1, 2, 2,  ..., 7, 6, 5],\n",
      "        [2, 1, 3,  ..., 8, 7, 6],\n",
      "        [2, 3, 1,  ..., 6, 5, 4],\n",
      "        ...,\n",
      "        [7, 8, 6,  ..., 1, 4, 5],\n",
      "        [6, 7, 5,  ..., 4, 1, 4],\n",
      "        [5, 6, 4,  ..., 5, 4, 1]]), tensor([1.0000e+04, 0.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00, 4.0000e+00,\n",
      "        5.0000e+00, 6.0000e+00, 7.0000e+00, 8.0000e+00, 9.0000e+00, 1.0000e+01,\n",
      "        1.1000e+01, 1.2000e+01, 1.3000e+01, 1.4000e+01, 1.5000e+01, 1.6000e+01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00]), 'shortest_paths'), (tensor([[11, 12, 12,  ..., 17, 16, 15],\n",
      "        [10, 11,  0,  ...,  0,  0,  0],\n",
      "        [10,  0, 11,  ..., 16, 15, 14],\n",
      "        ...,\n",
      "        [ 5,  0,  6,  ..., 11,  0,  0],\n",
      "        [ 6,  0,  7,  ...,  0, 11,  0],\n",
      "        [ 7,  0,  8,  ...,  0,  0, 11]]), tensor([ 1.0000e+04, -1.0000e+01, -9.0000e+00, -8.0000e+00, -7.0000e+00,\n",
      "        -6.0000e+00, -5.0000e+00, -4.0000e+00, -3.0000e+00, -2.0000e+00,\n",
      "        -1.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,\n",
      "         4.0000e+00,  5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00,\n",
      "         9.0000e+00,  1.0000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00]), 'ancestor_sp'), (tensor([[4, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 4, 5,  ..., 0, 0, 0],\n",
      "        [0, 3, 4,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 4, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 4, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 4]]), tensor([ 1.0000e+04, -3.0000e+00, -2.0000e+00, -1.0000e+00,  0.0000e+00,\n",
      "         1.0000e+00,  2.0000e+00,  3.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00]), 'sibling_sp')], token_to_node={0: 1, 1: 7, 2: 8, 3: 9, 4: 10, 5: 11, 6: 16, 7: 17, 8: 18, 9: 19, 10: 20, 11: 21, 12: 26, 13: 27, 14: 28, 15: 29, 16: 30, 17: 32, 18: 39, 19: 40, 20: 41, 21: 42, 22: 43, 23: 44, 24: 45, 25: 47, 26: 48, 27: 49, 28: 50, 29: 52, 30: 59, 31: 60, 32: 61, 33: 62, 34: 63, 35: 64, 36: 65, 37: 67, 38: 68, 39: 69, 40: 70, 41: 76, 42: 77, 43: 78, 44: 79, 45: 80, 46: 81, 47: 82})\n"
     ]
    }
   ],
   "source": [
    "files = glob(args.stage1_root + \"/**/*.pickle\", recursive=True)\n",
    "\n",
    "sample = pickle.load(open(files[0], \"rb\"))\n",
    "print(sample.goal)\n",
    "sample = vocab_transform(sample)\n",
    "sample = distances_transformer(sample)\n",
    "print(sample.goal)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b507fde4b7ba1e52694dcc45341e9929474d1b63f43d72f76eece533313bd962"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('griffon': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
